"""
Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–ª–æ—â–∞–¥–∏ –∑–∞—Å—Ç—Ä–æ–π–∫–∏
—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π sliding window –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
"""
import streamlit as st
import torch
import cv2
import numpy as np
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
import io
import os
import sys
from pathlib import Path
import tempfile
import math

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ –∑–∞—Å—Ç—Ä–æ–π–∫–∏ | –°–ø—É—Ç–Ω–∏–∫–æ–≤—ã–µ —Å–Ω–∏–º–∫–∏",
    page_icon="üèòÔ∏è",
    layout="wide"
)


# ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ====================

def add_safe_globals():
    """–†–∞–∑—Ä–µ—à–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É numpy –æ–±—ä–µ–∫—Ç–æ–≤"""
    try:
        import torch.serialization
        import numpy as np
        torch.serialization.add_safe_globals([np._core.multiarray.scalar])
    except:
        pass


@st.cache_resource
def load_trained_model(model_path, device='cpu'):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å U-Net
    """
    add_safe_globals()

    try:
        sys.path.append('.')
        from models.unet import UNet

        model = UNet(n_channels=3, n_classes=1, bilinear=True)

        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()

        model_info = {
            'epoch': checkpoint.get('epoch', 'unknown'),
            'val_iou': checkpoint.get('val_iou', 'unknown'),
            'type': 'U-Net with Bilinear Upsampling'
        }

        return model, model_info

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return None, None


def get_transform(img_size=512):
    """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞"""
    return A.Compose([
        A.Resize(img_size, img_size),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2(),
    ])


def create_overlay(image, mask, alpha=0.6):
    """–°–æ–∑–¥–∞—ë—Ç –Ω–∞–ª–æ–∂–µ–Ω–∏–µ –º–∞—Å–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

    if image.dtype != np.uint8:
        image = (image * 255).astype(np.uint8)

    overlay = image.copy()
    colored_mask = np.zeros_like(image)
    mask_binary = (mask > 0.5).astype(np.uint8)
    colored_mask[mask_binary == 1] = (255, 0, 0)  # –ö—Ä–∞—Å–Ω—ã–π —Ü–≤–µ—Ç

    cv2.addWeighted(colored_mask, alpha, overlay, 1 - alpha, 0, overlay)
    return overlay


def extract_geotiff_metadata(filepath):
    """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –º–∞—Å—à—Ç–∞–± –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö GeoTIFF"""
    try:
        import rasterio

        with rasterio.open(filepath) as src:
            if src.crs:
                # –ï—Å—Ç—å –≥–µ–æ–ø—Ä–∏–≤—è–∑–∫–∞
                pixel_size_x = src.transform[0]
                pixel_size_y = abs(src.transform[4])
                pixel_size = (pixel_size_x + pixel_size_y) / 2

                # –ï—Å–ª–∏ –≤ –≥—Ä–∞–¥—É—Å–∞—Ö - –≥—Ä—É–±—ã–π –ø–µ—Ä–µ–≤–æ–¥ –≤ –º–µ—Ç—Ä—ã
                if src.crs.is_geographic:
                    pixel_size *= 111000  # ~111 –∫–º –≤ –≥—Ä–∞–¥—É—Å–µ
                    return pixel_size, "geographic_crs"
                else:
                    return pixel_size, "projected_crs"
    except ImportError:
        return None, "rasterio_not_installed"
    except Exception:
        return None, "no_geotiff_metadata"

    return None, "not_geotiff"


def predict_sliding_window(model, image, device, patch_size=512, overlap=128):
    """
    Sliding window –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    """
    h, w = image.shape[:2]

    # –°–æ–∑–¥–∞—ë–º –ø—É—Å—Ç—É—é –º–∞—Å–∫—É –¥–ª—è –≤—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    full_prediction = np.zeros((h, w), dtype=np.float32)
    weight_map = np.zeros((h, w), dtype=np.float32)

    # –®–∞–≥ —Å —É—á—ë—Ç–æ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
    stride = patch_size - overlap

    # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ç—á–µ–π
    num_patches_h = math.ceil((h - overlap) / stride)
    num_patches_w = math.ceil((w - overlap) / stride)
    total_patches = num_patches_h * num_patches_w

    if total_patches == 0:
        return full_prediction

    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    progress_bar = st.progress(0, text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ 0/{total_patches} –ø–∞—Ç—á–µ–π")

    # –°–æ–∑–¥–∞—ë–º –≤–µ—Å–æ–≤—É—é –º–∞—Å–∫—É –¥–ª—è blending
    y_coords, x_coords = np.meshgrid(
        np.arange(patch_size),
        np.arange(patch_size),
        indexing='ij'
    )
    center = patch_size // 2
    distances = np.sqrt((y_coords - center) ** 2 + (x_coords - center) ** 2)
    patch_weights = np.clip(1 - distances / (patch_size / 2), 0, 1)

    transform = get_transform(patch_size)
    patch_counter = 0

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø–∞—Ç—á–∏
    for y in range(0, h, stride):
        for x in range(0, w, stride):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –ø–∞—Ç—á–∞
            y_end = min(y + patch_size, h)
            x_end = min(x + patch_size, w)
            patch_h = y_end - y
            patch_w = x_end - x

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –ø–∞—Ç—á–∏
            if patch_h < 64 or patch_w < 64:
                continue

            # –í—ã—Ä–µ–∑–∞–µ–º –ø–∞—Ç—á
            patch = image[y:y_end, x:x_end]

            # –ï—Å–ª–∏ –ø–∞—Ç—á –º–µ–Ω—å—à–µ –Ω—É–∂–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞–¥–¥–∏–Ω–≥
            if patch_h < patch_size or patch_w < patch_size:
                padded_patch = np.zeros((patch_size, patch_size, 3), dtype=patch.dtype)
                padded_patch[:patch_h, :patch_w] = patch
            else:
                padded_patch = patch

            # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            transformed = transform(image=padded_patch)
            input_tensor = transformed['image'].unsqueeze(0).to(device)

            with torch.no_grad():
                output = model(input_tensor)
                prediction = torch.sigmoid(output).squeeze().cpu().numpy()

            # –û–±—Ä–µ–∑–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–æ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—Ç—á–∞
            patch_pred = prediction[:patch_h, :patch_w]
            patch_weights_cropped = patch_weights[:patch_h, :patch_w]

            # –î–æ–±–∞–≤–ª—è–µ–º –∫ –ø–æ–ª–Ω–æ–π –º–∞—Å–∫–µ —Å –≤–µ—Å–∞–º–∏
            full_prediction[y:y_end, x:x_end] += patch_pred * patch_weights_cropped
            weight_map[y:y_end, x:x_end] += patch_weights_cropped

            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            patch_counter += 1
            progress = patch_counter / total_patches
            progress_bar.progress(
                progress,
                text=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {patch_counter}/{total_patches} –ø–∞—Ç—á–µ–π ({progress:.1%})"
            )

    progress_bar.empty()

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    weight_map[weight_map == 0] = 1  # –∏–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0
    full_prediction = full_prediction / weight_map

    return full_prediction


def smart_predict(model, image, device, patch_size=512):
    """
    –£–º–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: –≤—ã–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
    """
    h, w = image.shape[:2]

    # –î–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º sliding window
    if h > 1024 or w > 1024:
        st.info(f"üîÑ –ë–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({w}√ó{h}): –∏—Å–ø–æ–ª—å–∑—É—é sliding window")
        overlap = patch_size // 4  # 25% –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        return predict_sliding_window(model, image, device, patch_size, overlap)
    else:
        # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –ø—Ä–æ—Å—Ç–æ–π —Ä–µ—Å–∞–π–∑
        st.info(f"‚ö° –ú–∞–ª–µ–Ω—å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ({w}√ó{h}): –ø—Ä—è–º–æ–π –∞–Ω–∞–ª–∏–∑")
        transform = get_transform(patch_size)
        transformed = transform(image=image)
        input_tensor = transformed['image'].unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(input_tensor)
            prediction = torch.sigmoid(output).squeeze().cpu().numpy()

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
        prediction = cv2.resize(prediction, (w, h))
        return prediction


def count_buildings_opencv(binary_mask, min_area=25):
    """
    –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–¥–∞–Ω–∏–π —á–µ—Ä–µ–∑ OpenCV
    min_area: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –≤ –ø–∏–∫—Å–µ–ª—è—Ö –¥–ª—è —É—á—ë—Ç–∞ –æ–±—ä–µ–∫—Ç–∞
    """
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
    contours, _ = cv2.findContours(
        binary_mask.astype(np.uint8),
        cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE
    )

    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∫–æ–Ω—Ç—É—Ä—ã
    valid_contours = []
    building_areas_px = []

    for contour in contours:
        area = cv2.contourArea(contour)
        if area >= min_area:
            valid_contours.append(contour)
            building_areas_px.append(area)

    return len(valid_contours), building_areas_px


# ==================== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° ====================

def main():
    st.title("üèòÔ∏è –ê–Ω–∞–ª–∏–∑ –ø–ª–æ—â–∞–¥–∏ –∑–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–º —Å–Ω–∏–º–∫–∞–º")

    st.markdown("""
    **–í–Ω–∏–º–∞–Ω–∏–µ:** –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Å–Ω–∏–º–∫–æ–≤ —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º **0.3 –º/–ø–∏–∫—Å–µ–ª—å** (Inria Aerial Dataset).  
    –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–Ω–∏–º–∫–æ–≤ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç —Å–Ω–∏–∂–∞—Ç—å—Å—è.
    """)

    # ========== –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ==========
    with st.sidebar:
        st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

        # –¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        sensitivity = st.slider(
            "–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è",
            min_value=1,
            max_value=10,
            value=5,
            help="–í—ã—à–µ –∑–Ω–∞—á–µ–Ω–∏–µ - –º–µ–Ω—å—à–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤"
        )
        threshold = sensitivity / 10

        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Å–∫—Ä—ã—Ç–∞—è)
        with st.expander("‚ÑπÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏"):
            st.caption("""
            - –ú–æ–¥–µ–ª—å: U-Net Bilinear
            - –û–±—É—á–µ–Ω–∞ –Ω–∞: Inria Aerial Dataset
            - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ: 0.3 –º/–ø–∏–∫—Å–µ–ª—å
            - IoU: ~66%
            - –û–±—Ä–∞–±–æ—Ç–∫–∞: sliding window –¥–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            """)

    # ========== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò ==========
    MODEL_PATH = "./weights/best_model.pth"

    if not os.path.exists(MODEL_PATH):
        st.error(f"""
        ‚ö†Ô∏è **–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!**

        –ü—É—Ç—å: `{MODEL_PATH}`

        –ß—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å:
        ```bash
        python train_seg.py --train_images_dir ./data/train/images ...
        ```
        """)
        return

    if 'model' not in st.session_state:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏..."):
            model, model_info = load_trained_model(MODEL_PATH, 'cpu')
            if model:
                st.session_state['model'] = model
                st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
                return

    # ========== –ó–ê–ì–†–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ==========
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–π —Å–Ω–∏–º–æ–∫")

    uploaded_file = st.file_uploader(
        " ",
        type=['png', 'jpg', 'jpeg', 'tif', 'tiff'],
        label_visibility="collapsed",
        help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: PNG, JPG, TIFF, GeoTIFF"
    )

    if uploaded_file:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            temp_path = tmp_file.name

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∫–∞–∑–∞
            image = Image.open(temp_path)
            image_np = np.array(image.convert('RGB'))
            h, w = image_np.shape[:2]

            col1, col2 = st.columns(2)

            with col1:
                st.subheader("–í–∞—à —Å–Ω–∏–º–æ–∫")
                st.image(image_np, use_container_width=True)
                st.caption(f"–†–∞–∑–º–µ—Ä: {w} √ó {h} –ø–∏–∫—Å–µ–ª–µ–π")

            # ========== –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ú–ê–°–®–¢–ê–ë–ê ==========
            st.subheader("üìè –£–∫–∞–∂–∏—Ç–µ –º–∞—Å—à—Ç–∞–± —Å–Ω–∏–º–∫–∞")

            pixel_size = None
            scale_source = ""

            # –ü–æ–ø—ã—Ç–∫–∞ 1: –ò–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö GeoTIFF
            if uploaded_file.name.lower().endswith(('.tif', '.tiff')):
                with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö GeoTIFF..."):
                    pixel_size, metadata_status = extract_geotiff_metadata(temp_path)

                    if pixel_size:
                        st.success(f"‚úÖ –ú–∞—Å—à—Ç–∞–± –æ–ø—Ä–µ–¥–µ–ª—ë–Ω –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {pixel_size:.4f} –º/–ø–∏–∫—Å–µ–ª—å")
                        scale_source = "geotiff_metadata"
                    else:
                        st.info("‚ÑπÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–∞—Å—à—Ç–∞–± –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")

            # –ï—Å–ª–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö - –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
            if pixel_size is None:
                tab1, tab2, tab3 = st.tabs([
                    "üìê –ú–µ—Ç—Ä–æ–≤ –Ω–∞ –ø–∏–∫—Å–µ–ª—å",
                    "üìè –†–∞–∑–º–µ—Ä—ã —É—á–∞—Å—Ç–∫–∞",
                    "‚ÑπÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
                ])

                with tab1:
                    st.markdown("**–£–∫–∞–∂–∏—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–Ω–∏–º–∫–∞:**")

                    # –ü—Ä–∏–º–µ—Ä—ã —Ç–∏–ø–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        if st.button("0.3 –º", use_container_width=True, key="btn_03"):
                            st.session_state['selected_pixel_size'] = 0.3
                            st.session_state['selected_scale_source'] = "inria_default"
                    with col_b:
                        if st.button("0.5 –º", use_container_width=True, key="btn_05"):
                            st.session_state['selected_pixel_size'] = 0.5
                            st.session_state['selected_scale_source'] = "manual"
                    with col_c:
                        if st.button("1.0 –º", use_container_width=True, key="btn_10"):
                            st.session_state['selected_pixel_size'] = 1.0
                            st.session_state['selected_scale_source'] = "manual"

                    # –†—É—á–Ω–æ–π –≤–≤–æ–¥
                    manual_size = st.number_input(
                        "–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ —Å–≤–æ—ë –∑–Ω–∞—á–µ–Ω–∏–µ:",
                        min_value=0.01,
                        max_value=100.0,
                        value=0.3,
                        step=0.01,
                        format="%.3f",
                        key="manual_input"
                    )

                    if st.button("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ", key="use_manual"):
                        st.session_state['selected_pixel_size'] = manual_size
                        st.session_state['selected_scale_source'] = "manual"

                with tab2:
                    st.markdown("**–£–∫–∞–∂–∏—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —É—á–∞—Å—Ç–∫–∞:**")

                    col_x, col_y = st.columns(2)
                    with col_x:
                        width_m = st.number_input(
                            "–®–∏—Ä–∏–Ω–∞ —É—á–∞—Å—Ç–∫–∞ (–º)",
                            min_value=1.0,
                            max_value=100000.0,
                            value=100.0,
                            step=1.0,
                            key="width_input"
                        )
                    with col_y:
                        height_m = st.number_input(
                            "–í—ã—Å–æ—Ç–∞ —É—á–∞—Å—Ç–∫–∞ (–º)",
                            min_value=1.0,
                            max_value=100000.0,
                            value=100.0,
                            step=1.0,
                            key="height_input"
                        )

                    if width_m and height_m and w > 0 and h > 0:
                        pixel_size_x = width_m / w
                        pixel_size_y = height_m / h
                        pixel_size_avg = (pixel_size_x + pixel_size_y) / 2

                        st.info(f"–†–∞—Å—á—ë—Ç–Ω—ã–π –º–∞—Å—à—Ç–∞–±: {pixel_size_avg:.4f} –º/–ø–∏–∫—Å–µ–ª—å")

                        if st.button("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞—Å—á—ë—Ç–Ω—ã–π –º–∞—Å—à—Ç–∞–±", key="use_calc"):
                            st.session_state['selected_pixel_size'] = pixel_size_avg
                            st.session_state['selected_scale_source'] = "calculated"

                with tab3:
                    st.markdown("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–∞—Å—à—Ç–∞–±—É:**")

                    st.write("""
                    **–û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏:** 0.3 –º/–ø–∏–∫—Å–µ–ª—å

                    **–¢–∏–ø–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:**
                    - Maxar/Planet: 0.3-0.5 –º
                    - Airbus: 0.5-1.5 –º  
                    - Sentinel-2: 10 –º
                    - –î—Ä–æ–Ω—ã: 0.01-0.1 –º

                    **Inria Aerial Dataset:** 0.3 –º/–ø–∏–∫—Å–µ–ª—å
                    """)

                    if st.button("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 0.3 –º (Inria)", key="use_inria"):
                        st.session_state['selected_pixel_size'] = 0.3
                        st.session_state['selected_scale_source'] = "inria_default"

            # ========== –ê–ù–ê–õ–ò–ó ==========
            # –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –∞–Ω–∞–ª–∏–∑–∞
            st.markdown("---")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–Ω –ª–∏ –º–∞—Å—à—Ç–∞–± (–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∏–∑ session_state)
            current_pixel_size = pixel_size
            current_scale_source = scale_source

            if current_pixel_size is None and 'selected_pixel_size' in st.session_state:
                current_pixel_size = st.session_state['selected_pixel_size']
                current_scale_source = st.session_state.get('selected_scale_source', 'manual')

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –≤—ã–±—Ä–∞–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–±
            if current_pixel_size is not None:
                st.info(f"üìè –í—ã–±—Ä–∞–Ω–Ω—ã–π –º–∞—Å—à—Ç–∞–±: **{current_pixel_size:.4f} –º/–ø–∏–∫—Å–µ–ª—å**")

                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –º–∞—Å—à—Ç–∞–± –Ω–µ 0.3
                if abs(current_pixel_size - 0.3) > 0.05:  # –ï—Å–ª–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 5%
                    st.warning(f"""
                    ‚ö†Ô∏è **–í–Ω–∏–º–∞–Ω–∏–µ:** –í—ã —É–∫–∞–∑–∞–ª–∏ –º–∞—Å—à—Ç–∞–± {current_pixel_size:.3f} –º/–ø–∏–∫—Å–µ–ª—å

                    –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è **0.3 –º/–ø–∏–∫—Å–µ–ª—å** (Inria Aerial Dataset).
                    –î–ª—è —ç—Ç–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∂–µ.
                    """)

            # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", use_container_width=True):

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–∞—Å—à—Ç–∞–± –≤—ã–±—Ä–∞–Ω
                if current_pixel_size is None:
                    st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ —É–∫–∞–∂–∏—Ç–µ –º–∞—Å—à—Ç–∞–± —Å–Ω–∏–º–∫–∞!")
                    st.stop()

                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
                    try:
                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å sliding window
                        model = st.session_state['model']

                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º patch_size=512 –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
                        prediction = smart_predict(model, image_np, 'cpu', patch_size=512)

                        # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
                        binary_mask = (prediction > threshold).astype(np.uint8)

                        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
                        overlay = create_overlay(image_np, binary_mask, alpha=0.6)

                        # –†–∞—Å—á—ë—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø–ª–æ—â–∞–¥–∏
                        building_pixels = np.sum(binary_mask)
                        area_m2 = building_pixels * (current_pixel_size ** 2)
                        coverage = (building_pixels / binary_mask.size) * 100

                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—ä–µ–∫—Ç–∞–º
                        num_buildings, building_areas_px = count_buildings_opencv(binary_mask, min_area=25)

                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ø–ª–æ—â–∞–¥–∏ –≤ –º¬≤
                        building_areas_m2 = [area * (current_pixel_size ** 2) for area in building_areas_px]

                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        with col2:
                            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")

                            # –í–∫–ª–∞–¥–∫–∏
                            tab_viz, tab_stats = st.tabs(["–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è", "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"])

                            with tab_viz:
                                st.image(overlay, use_container_width=True)
                                st.caption(f"–ù–∞–π–¥–µ–Ω–æ –∑–¥–∞–Ω–∏–π: {num_buildings}")

                            with tab_stats:
                                # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                                st.metric(
                                    "–ü–ª–æ—â–∞–¥—å –∑–∞—Å—Ç—Ä–æ–π–∫–∏",
                                    f"{area_m2:,.0f} –º¬≤",
                                    delta=None,
                                    help=f"–ü—Ä–∏ {current_pixel_size:.3f} –º/–ø–∏–∫—Å–µ–ª—å"
                                )

                                st.metric(
                                    "–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞—Å—Ç—Ä–æ–π–∫–∏",
                                    f"{coverage:.1f}%"
                                )

                                st.metric(
                                    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–¥–∞–Ω–∏–π",
                                    f"{num_buildings}"
                                )

                                st.metric(
                                    "–ü–∏–∫—Å–µ–ª–∏ –∑–¥–∞–Ω–∏–π",
                                    f"{building_pixels:,}"
                                )

                                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –µ—Å–ª–∏ –µ—Å—Ç—å –∑–¥–∞–Ω–∏—è
                                if num_buildings > 0:
                                    st.markdown("---")
                                    st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–¥–∞–Ω–∏—è–º")

                                    col_stat1, col_stat2 = st.columns(2)
                                    with col_stat1:
                                        st.write(f"**–°—Ä–µ–¥–Ω—è—è –ø–ª–æ—â–∞–¥—å:** {np.mean(building_areas_m2):.0f} –º¬≤")
                                        st.write(f"**–ú–µ–¥–∏–∞–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å:** {np.median(building_areas_m2):.0f} –º¬≤")
                                    with col_stat2:
                                        st.write(f"**–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å:** {np.min(building_areas_m2):.0f} –º¬≤")
                                        st.write(f"**–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å:** {np.max(building_areas_m2):.0f} –º¬≤")

                                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞—Å—à—Ç–∞–±–µ
                                st.info(f"""
                                **–ò—Å—Ç–æ—á–Ω–∏–∫ –º–∞—Å—à—Ç–∞–±–∞:** {current_scale_source}
                                **–ó–Ω–∞—á–µ–Ω–∏–µ:** {current_pixel_size:.4f} –º/–ø–∏–∫—Å–µ–ª—å
                                **–ü–ª–æ—â–∞–¥—å –ø–∏–∫—Å–µ–ª—è:** {current_pixel_size ** 2:.6f} –º¬≤
                                """)

                        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                        st.subheader("üíæ –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")

                        col_dl1, col_dl2 = st.columns(2)

                        with col_dl1:
                            # –ú–∞—Å–∫–∞
                            mask_pil = Image.fromarray((binary_mask * 255).astype(np.uint8))
                            mask_bytes = io.BytesIO()
                            mask_pil.save(mask_bytes, format='PNG')

                            st.download_button(
                                "üì• –ú–∞—Å–∫–∞ –∑–¥–∞–Ω–∏–π (PNG)",
                                data=mask_bytes.getvalue(),
                                file_name="building_mask.png",
                                mime="image/png"
                            )

                        with col_dl2:
                            # –û—Ç—á—ë—Ç
                            report = f"""–ê–ù–ê–õ–ò–ó –ü–õ–û–©–ê–î–ò –ó–ê–°–¢–†–û–ô–ö–ò

–§–∞–π–ª: {uploaded_file.name}
–î–∞—Ç–∞: {st.session_state.get('analysis_time', 'N/A')}

–†–ê–ó–ú–ï–†–´:
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {w} √ó {h} –ø–∏–∫—Å–µ–ª–µ–π
- –ú–∞—Å—à—Ç–∞–±: {current_pixel_size:.4f} –º/–ø–∏–∫—Å–µ–ª—å (–∏—Å—Ç–æ—á–Ω–∏–∫: {current_scale_source})
- –û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –∫–∞–¥—Ä–∞: {(w * h * current_pixel_size ** 2):,.0f} –º¬≤

–†–ï–ó–£–õ–¨–¢–ê–¢–´:
- –ü–ª–æ—â–∞–¥—å –∑–∞—Å—Ç—Ä–æ–π–∫–∏: {area_m2:,.0f} –º¬≤
- –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞—Å—Ç—Ä–æ–π–∫–∏: {coverage:.1f}%
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–¥–∞–Ω–∏–π: {num_buildings}
- –ü–∏–∫—Å–µ–ª–∏ –∑–¥–∞–Ω–∏–π: {building_pixels:,}

–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ó–î–ê–ù–ò–Ø–ú:
- –°—Ä–µ–¥–Ω—è—è –ø–ª–æ—â–∞–¥—å: {np.mean(building_areas_m2) if num_buildings > 0 else 0:.0f} –º¬≤
- –ú–µ–¥–∏–∞–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å: {np.median(building_areas_m2) if num_buildings > 0 else 0:.0f} –º¬≤
- –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å: {np.min(building_areas_m2) if num_buildings > 0 else 0:.0f} –º¬≤
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å: {np.max(building_areas_m2) if num_buildings > 0 else 0:.0f} –º¬≤

–ü–ê–†–ê–ú–ï–¢–†–´:
- –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {sensitivity}/10
- –ü–æ—Ä–æ–≥: {threshold:.2f}
- –ú–æ–¥–µ–ª—å: U-Net Bilinear
- –û–±—Ä–∞–±–æ—Ç–∫–∞: {'Sliding window' if h > 1024 or w > 1024 else '–ü—Ä—è–º–æ–π –∞–Ω–∞–ª–∏–∑'}
"""

                            st.download_button(
                                "üì• –û—Ç—á—ë—Ç (TXT)",
                                data=report,
                                file_name="building_analysis.txt",
                                mime="text/plain"
                            )

                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")

        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            try:
                os.unlink(temp_path)
            except:
                pass

    else:
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–π —Å–Ω–∏–º–æ–∫ –¥–ª—è –Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∞")

        with st.expander("üìã –ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ —Å–∏—Å—Ç–µ–º–µ"):
            st.markdown("""
            ### –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:

            1. **–ó–∞–≥—Ä—É–∂–∞–µ—Ç–µ** —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–π —Å–Ω–∏–º–æ–∫
            2. **–£–∫–∞–∑—ã–≤–∞–µ—Ç–µ –º–∞—Å—à—Ç–∞–±** –æ–¥–Ω–∏–º –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤:
               - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö GeoTIFF
               - –í—Ä—É—á–Ω—É—é: "–º–µ—Ç—Ä–æ–≤ –Ω–∞ –ø–∏–∫—Å–µ–ª—å"
               - –ß–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —É—á–∞—Å—Ç–∫–∞
            3. **–ü–æ–ª—É—á–∞–µ—Ç–µ** –ø–ª–æ—â–∞–¥—å –∑–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ –º¬≤

            ### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
            - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —Å–Ω–∏–º–∫–æ–≤ –∏–∑ Inria Aerial Dataset (0.3 –º/–ø–∏–∫—Å)
            - –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–Ω–∏–º–∫–æ–≤ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∂–µ
            - –î–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **Sliding window** - —Å–Ω–∏–º–æ–∫ —Ä–∞–∑—Ä–µ–∑–∞–µ—Ç—Å—è –Ω–∞ –ø–∞—Ç—á–∏ 512x512 –ø–∏–∫—Å–µ–ª–µ–π, –¥–ª—è –ø–∞—Ç—á–µ–π —Å—Ç—Ä–æ—è—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –∑–∞—Ç–µ–º –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
            - –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–∞–¥–¥–∏–Ω–≥

            ### –§–æ—Ä–º–∞—Ç—ã:
            - PNG, JPG, JPEG (–æ–±—ã—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
            - TIFF, GeoTIFF (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
            """)


if __name__ == '__main__':
    import datetime

    st.session_state['analysis_time'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    if 'selected_pixel_size' not in st.session_state:
        st.session_state['selected_pixel_size'] = None
    if 'selected_scale_source' not in st.session_state:
        st.session_state['selected_scale_source'] = ""

    main()